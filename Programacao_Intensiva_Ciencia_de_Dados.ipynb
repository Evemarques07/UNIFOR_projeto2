{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Programa√ß√£o para Ci√™ncia de Dados ‚Äì MBA Ci√™ncia de Dados, Universidade de Fortaleza\n",
    "\n",
    "**Instrutor:** C√°ssio Pinheiro  \n",
    "**Carga hor√°ria:** 28h  \n",
    "**Formato:** Intensivo (presencial ou h√≠brido)  \n",
    "**Linguagem:** Python  \n",
    "**Ambiente:** Jupyter Notebook / Google Colab\n",
    "\n",
    "Este notebook integra os cinco m√≥dulos da disciplina **Programa√ß√£o para Ci√™ncia de Dados**, combinando teoria t√©cnica, exemplos pr√°ticos detalhados e desafios aplicados usando datasets reais.\n",
    "\n",
    "---\n",
    "\n",
    "## üìë √çndice\n",
    "\n",
    "1. [M√≥dulo 1 - Fundamentos de Programa√ß√£o com Python](#modulo1)\n",
    "2. [M√≥dulo 2 - Manipula√ß√£o Avan√ßada com Pandas e NumPy](#modulo2)\n",
    "3. [M√≥dulo 3 - Visualiza√ß√£o e An√°lise Explorat√≥ria de Dados](#modulo3)\n",
    "4. [M√≥dulo 4 - An√°lise Estat√≠stica e Machine Learning](#modulo4)\n",
    "5. [M√≥dulo 5 - Projeto Final Integrado](#modulo5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modulo1'></a>\n",
    "# üß© M√≥dulo 1 ‚Äì Fundamentos de Programa√ß√£o com Python\n",
    "\n",
    "Neste m√≥dulo, abordamos a base da linguagem Python aplicada √† ci√™ncia de dados.  \n",
    "Exploramos tipos de dados, estruturas de controle, fun√ß√µes, compreens√£o de listas, e boas pr√°ticas.\n",
    "\n",
    "## 1.1 Tipos de Dados e Opera√ß√µes B√°sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma: 13\n",
      "Subtra√ß√£o: 7\n",
      "Multiplica√ß√£o: 30\n",
      "Divis√£o: 3.33\n",
      "Divis√£o inteira: 3\n",
      "Resto: 1\n",
      "Pot√™ncia: 1000\n"
     ]
    }
   ],
   "source": [
    "# Tipos de dados e opera√ß√µes\n",
    "x, y = 10, 3\n",
    "print(f\"Soma: {x + y}\")\n",
    "print(f\"Subtra√ß√£o: {x - y}\")\n",
    "print(f\"Multiplica√ß√£o: {x * y}\")\n",
    "print(f\"Divis√£o: {x / y:.2f}\")\n",
    "print(f\"Divis√£o inteira: {x // y}\")\n",
    "print(f\"Resto: {x % y}\")\n",
    "print(f\"Pot√™ncia: {x ** y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Estruturas de Dados Fundamentais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista original: [1, 2, 3, 4, 5]\n",
      "Primeiro elemento: 1\n",
      "√öltimos dois: [4, 5]\n",
      "Slice [1:4]: [2, 3, 4]\n",
      "Ap√≥s opera√ß√µes: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Listas\n",
    "numeros = [1, 2, 3, 4, 5]\n",
    "print(\"Lista original:\", numeros)\n",
    "print(\"Primeiro elemento:\", numeros[0])\n",
    "print(\"√öltimos dois:\", numeros[-2:])\n",
    "print(\"Slice [1:4]:\", numeros[1:4])\n",
    "\n",
    "# Opera√ß√µes com listas\n",
    "numeros.append(6)\n",
    "numeros.extend([7, 8])\n",
    "numeros.insert(0, 0)\n",
    "print(\"Ap√≥s opera√ß√µes:\", numeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rios\n",
    "aluno = {\n",
    "    'nome': 'Ana Silva',\n",
    "    'idade': 28,\n",
    "    'curso': 'MBA Ci√™ncia de Dados',\n",
    "    'notas': [8.5, 9.0, 7.5, 8.0]\n",
    "}\n",
    "\n",
    "print(f\"Nome: {aluno['nome']}\")\n",
    "print(f\"M√©dia: {sum(aluno['notas']) / len(aluno['notas']):.2f}\")\n",
    "\n",
    "# Itera√ß√£o\n",
    "for chave, valor in aluno.items():\n",
    "    print(f\"{chave}: {valor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuplas e Sets\n",
    "coordenadas = (10.5, 20.3)\n",
    "x, y = coordenadas  # Unpacking\n",
    "print(f\"X: {x}, Y: {y}\")\n",
    "\n",
    "# Sets - opera√ß√µes de conjunto\n",
    "set_a = {1, 2, 3, 4, 5}\n",
    "set_b = {4, 5, 6, 7, 8}\n",
    "\n",
    "print(f\"Uni√£o: {set_a | set_b}\")\n",
    "print(f\"Interse√ß√£o: {set_a & set_b}\")\n",
    "print(f\"Diferen√ßa: {set_a - set_b}\")\n",
    "print(f\"Diferen√ßa sim√©trica: {set_a ^ set_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Estruturas de Controle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estruturas condicionais e la√ßos\n",
    "valores = [10, 15, 20, 25, 30]\n",
    "\n",
    "for v in valores:\n",
    "    if v % 2 == 0:\n",
    "        print(f\"{v} √© par\")\n",
    "    else:\n",
    "        print(f\"{v} √© √≠mpar\")\n",
    "\n",
    "# While loop\n",
    "contador = 0\n",
    "soma = 0\n",
    "while contador < 5:\n",
    "    soma += contador\n",
    "    contador += 1\n",
    "print(f\"Soma de 0 a 4: {soma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Compreens√µes e Programa√ß√£o Funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension\n",
    "quadrados = [x**2 for x in range(1, 11)]\n",
    "print(\"Quadrados:\", quadrados)\n",
    "\n",
    "# Com condi√ß√£o\n",
    "pares = [x for x in quadrados if x % 2 == 0]\n",
    "print(\"Apenas pares:\", pares)\n",
    "\n",
    "# Dict comprehension\n",
    "quadrados_dict = {x: x**2 for x in range(1, 6)}\n",
    "print(\"Dicion√°rio de quadrados:\", quadrados_dict)\n",
    "\n",
    "# Set comprehension\n",
    "vogais = {letra.lower() for palavra in ['Python', 'Data', 'Science'] \n",
    "          for letra in palavra if letra.lower() in 'aeiou'}\n",
    "print(\"Vogais √∫nicas:\", vogais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes lambda e map/filter/reduce\n",
    "dobro = lambda x: x * 2\n",
    "numeros_dobrados = list(map(dobro, [1, 2, 3, 4]))\n",
    "print(\"Dobrados:\", numeros_dobrados)\n",
    "\n",
    "# Filter\n",
    "pares_filter = list(filter(lambda x: x % 2 == 0, range(10)))\n",
    "print(\"Pares com filter:\", pares_filter)\n",
    "\n",
    "# Reduce\n",
    "from functools import reduce\n",
    "produto = reduce(lambda x, y: x * y, [1, 2, 3, 4, 5])\n",
    "print(f\"Produto de 1 a 5: {produto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Fun√ß√µes Avan√ßadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o com argumentos padr√£o e documenta√ß√£o\n",
    "def calcular_estatisticas(dados, incluir_media=True, incluir_mediana=False):\n",
    "    \"\"\"\n",
    "    Calcula estat√≠sticas b√°sicas de uma lista de n√∫meros.\n",
    "    \n",
    "    Args:\n",
    "        dados (list): Lista de n√∫meros\n",
    "        incluir_media (bool): Se True, calcula a m√©dia\n",
    "        incluir_mediana (bool): Se True, calcula a mediana\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicion√°rio com as estat√≠sticas calculadas\n",
    "    \"\"\"\n",
    "    resultado = {\n",
    "        'minimo': min(dados),\n",
    "        'maximo': max(dados),\n",
    "        'quantidade': len(dados)\n",
    "    }\n",
    "    \n",
    "    if incluir_media:\n",
    "        resultado['media'] = sum(dados) / len(dados)\n",
    "    \n",
    "    if incluir_mediana:\n",
    "        dados_ordenados = sorted(dados)\n",
    "        n = len(dados_ordenados)\n",
    "        if n % 2 == 0:\n",
    "            resultado['mediana'] = (dados_ordenados[n//2-1] + dados_ordenados[n//2]) / 2\n",
    "        else:\n",
    "            resultado['mediana'] = dados_ordenados[n//2]\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Teste\n",
    "dados = [10, 20, 30, 40, 50]\n",
    "stats = calcular_estatisticas(dados, incluir_mediana=True)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Manipula√ß√£o de Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrita de arquivo\n",
    "with open(\"exemplo.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"Disciplina: Programa√ß√£o para Ci√™ncia de Dados\\n\")\n",
    "    f.write(\"Instrutor: C√°ssio Pinheiro\\n\")\n",
    "    f.write(\"Universidade de Fortaleza\\n\")\n",
    "\n",
    "# Leitura de arquivo\n",
    "with open(\"exemplo.txt\", \"r\", encoding='utf-8') as f:\n",
    "    conteudo = f.read()\n",
    "    print(conteudo)\n",
    "\n",
    "# Leitura linha por linha\n",
    "with open(\"exemplo.txt\", \"r\", encoding='utf-8') as f:\n",
    "    for i, linha in enumerate(f, 1):\n",
    "        print(f\"Linha {i}: {linha.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modulo2'></a>\n",
    "# üßÆ M√≥dulo 2 ‚Äì Manipula√ß√£o Avan√ßada com Pandas e NumPy\n",
    "\n",
    "Introdu√ß√£o √† manipula√ß√£o de dados estruturados com as bibliotecas `pandas` e `numpy`.  \n",
    "Inclui leitura, limpeza, transforma√ß√£o, agrega√ß√µes e joins.\n",
    "\n",
    "## 2.1 NumPy - Fundamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cria√ß√£o de arrays\n",
    "arr1d = np.array([1, 2, 3, 4, 5])\n",
    "arr2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "zeros = np.zeros((3, 4))\n",
    "ones = np.ones((2, 3))\n",
    "identidade = np.eye(3)\n",
    "aleatorio = np.random.rand(3, 3)\n",
    "\n",
    "print(\"Array 1D:\", arr1d)\n",
    "print(\"\\nArray 2D:\\n\", arr2d)\n",
    "print(\"\\nZeros:\\n\", zeros)\n",
    "print(\"\\nIdentidade:\\n\", identidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opera√ß√µes vetorizadas (muito mais r√°pidas que loops)\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"Original:\", arr)\n",
    "print(\"Multiplicado por 2:\", arr * 2)\n",
    "print(\"Ao quadrado:\", arr ** 2)\n",
    "print(\"Mais 10:\", arr + 10)\n",
    "\n",
    "# Opera√ß√µes entre arrays\n",
    "arr2 = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Soma de arrays:\", arr + arr2)\n",
    "print(\"Produto elemento a elemento:\", arr * arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexa√ß√£o e fatiamento\n",
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Indexa√ß√£o booleana\n",
    "maiores_que_5 = arr[arr > 5]\n",
    "print(\"Maiores que 5:\", maiores_que_5)\n",
    "\n",
    "pares = arr[arr % 2 == 0]\n",
    "print(\"Pares:\", pares)\n",
    "\n",
    "# Fancy indexing\n",
    "indices = [0, 2, 4, 6]\n",
    "elementos = arr[indices]\n",
    "print(\"Elementos nos √≠ndices [0,2,4,6]:\", elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opera√ß√µes estat√≠sticas\n",
    "np.random.seed(42)\n",
    "dados = np.random.randn(1000)\n",
    "\n",
    "print(f\"M√©dia: {np.mean(dados):.4f}\")\n",
    "print(f\"Mediana: {np.median(dados):.4f}\")\n",
    "print(f\"Desvio padr√£o: {np.std(dados):.4f}\")\n",
    "print(f\"Vari√¢ncia: {np.var(dados):.4f}\")\n",
    "print(f\"M√≠nimo: {np.min(dados):.4f}\")\n",
    "print(f\"M√°ximo: {np.max(dados):.4f}\")\n",
    "print(f\"Percentil 25: {np.percentile(dados, 25):.4f}\")\n",
    "print(f\"Percentil 75: {np.percentile(dados, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ålgebra linear\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Matriz A:\\n\", A)\n",
    "print(\"\\nMatriz B:\\n\", B)\n",
    "\n",
    "# Multiplica√ß√£o de matrizes\n",
    "produto = np.dot(A, B)\n",
    "print(\"\\nA √ó B:\\n\", produto)\n",
    "\n",
    "# Determinante\n",
    "det_A = np.linalg.det(A)\n",
    "print(f\"\\nDeterminante de A: {det_A}\")\n",
    "\n",
    "# Inversa\n",
    "inv_A = np.linalg.inv(A)\n",
    "print(\"\\nInversa de A:\\n\", inv_A)\n",
    "\n",
    "# Autovalores e autovetores\n",
    "autovalores, autovetores = np.linalg.eig(A)\n",
    "print(\"\\nAutovalores:\", autovalores)\n",
    "print(\"\\nAutovetores:\\n\", autovetores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pandas - DataFrames e Series\n",
    "\n",
    "Vamos trabalhar com os datasets reais dispon√≠veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Leitura do dataset Titanic\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_titanic \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leitura do dataset Titanic\n",
    "df_titanic = pd.read_csv(\"datasets/titanic.csv\")\n",
    "\n",
    "print(\"Primeiras linhas:\")\n",
    "print(df_titanic.head())\n",
    "\n",
    "print(\"\\nInforma√ß√µes do dataset:\")\n",
    "print(df_titanic.info())\n",
    "\n",
    "print(\"\\nEstat√≠sticas descritivas:\")\n",
    "print(df_titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(df_titanic.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentual de valores nulos:\")\n",
    "print((df_titanic.isnull().sum() / len(df_titanic) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de dados\n",
    "df = df_titanic.copy()\n",
    "\n",
    "# Preencher idade com a m√©dia\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "# Mapear sexo para portugu√™s\n",
    "df['Sex'] = df['Sex'].map({'male': 'Masculino', 'female': 'Feminino'})\n",
    "\n",
    "# Criar faixa et√°ria\n",
    "df['FaixaEtaria'] = pd.cut(df['Age'], bins=[0, 18, 35, 60, 100], \n",
    "                            labels=['Crian√ßa/Adolescente', 'Jovem', 'Adulto', 'Idoso'])\n",
    "\n",
    "print(\"Dataset ap√≥s limpeza:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sele√ß√£o e filtragem\n",
    "# Selecionar colunas espec√≠ficas\n",
    "df_subset = df[['PassengerId', 'Pclass', 'Sex', 'Age', 'Survived']]\n",
    "print(\"Subset de colunas:\")\n",
    "print(df_subset.head())\n",
    "\n",
    "# Filtrar passageiros que sobreviveram\n",
    "sobreviventes = df[df['Survived'] == 1]\n",
    "print(f\"\\nTotal de sobreviventes: {len(sobreviventes)}\")\n",
    "\n",
    "# M√∫ltiplas condi√ß√µes\n",
    "mulheres_primeira_classe = df[(df['Sex'] == 'Feminino') & (df['Pclass'] == 1)]\n",
    "print(f\"\\nMulheres na primeira classe: {len(mulheres_primeira_classe)}\")\n",
    "print(f\"Taxa de sobreviv√™ncia: {mulheres_primeira_classe['Survived'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamentos e agrega√ß√µes\n",
    "print(\"Taxa de sobreviv√™ncia por classe:\")\n",
    "por_classe = df.groupby('Pclass')['Survived'].agg(['mean', 'count'])\n",
    "por_classe.columns = ['TaxaSobrevivencia', 'Total']\n",
    "print(por_classe)\n",
    "\n",
    "print(\"\\nTaxa de sobreviv√™ncia por classe e sexo:\")\n",
    "por_classe_sexo = df.groupby(['Pclass', 'Sex'])['Survived'].agg(['mean', 'count'])\n",
    "por_classe_sexo.columns = ['TaxaSobrevivencia', 'Total']\n",
    "print(por_classe_sexo)\n",
    "\n",
    "# M√∫ltiplas agrega√ß√µes\n",
    "print(\"\\nEstat√≠sticas de idade por classe:\")\n",
    "stats_idade = df.groupby('Pclass')['Age'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "print(stats_idade.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 An√°lise do Dataset de Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset de vendas\n",
    "df_vendas = pd.read_csv(\"datasets/vendas.csv\")\n",
    "df_vendas['Data'] = pd.to_datetime(df_vendas['Data'])\n",
    "\n",
    "print(\"Dataset de Vendas:\")\n",
    "print(df_vendas.head())\n",
    "print(f\"\\nPer√≠odo: {df_vendas['Data'].min()} a {df_vendas['Data'].max()}\")\n",
    "print(f\"Total de registros: {len(df_vendas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise por regi√£o\n",
    "print(\"Desempenho por Regi√£o:\")\n",
    "por_regiao = df_vendas.groupby('Regiao').agg({\n",
    "    'Receita': ['sum', 'mean'],\n",
    "    'Lucro': ['sum', 'mean'],\n",
    "    'Qtd_Vendida': 'sum'\n",
    "}).round(2)\n",
    "print(por_regiao)\n",
    "\n",
    "# Calcular margem de lucro\n",
    "margem_por_regiao = (df_vendas.groupby('Regiao')['Lucro'].sum() / \n",
    "                     df_vendas.groupby('Regiao')['Receita'].sum() * 100)\n",
    "print(\"\\nMargem de Lucro por Regi√£o:\")\n",
    "print(margem_por_regiao.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise por produto\n",
    "print(\"Top 5 Produtos por Receita:\")\n",
    "top_produtos = df_vendas.groupby('Produto').agg({\n",
    "    'Receita': 'sum',\n",
    "    'Lucro': 'sum',\n",
    "    'Qtd_Vendida': 'sum'\n",
    "}).sort_values('Receita', ascending=False)\n",
    "print(top_produtos)\n",
    "\n",
    "# Margem por produto\n",
    "top_produtos['Margem_%'] = (top_produtos['Lucro'] / top_produtos['Receita'] * 100).round(2)\n",
    "print(\"\\nProdutos com margem:\")\n",
    "print(top_produtos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise temporal\n",
    "df_vendas['Ano'] = df_vendas['Data'].dt.year\n",
    "df_vendas['Mes'] = df_vendas['Data'].dt.month\n",
    "df_vendas['Trimestre'] = df_vendas['Data'].dt.quarter\n",
    "\n",
    "print(\"Receita por Ano:\")\n",
    "por_ano = df_vendas.groupby('Ano')['Receita'].sum()\n",
    "print(por_ano)\n",
    "\n",
    "print(\"\\nCrescimento ano a ano:\")\n",
    "crescimento = por_ano.pct_change() * 100\n",
    "print(crescimento.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempenho por vendedor\n",
    "print(\"Ranking de Vendedores:\")\n",
    "ranking_vendedores = df_vendas.groupby('Vendedor').agg({\n",
    "    'Receita': 'sum',\n",
    "    'Lucro': 'sum',\n",
    "    'Qtd_Vendida': 'sum'\n",
    "}).sort_values('Receita', ascending=False)\n",
    "ranking_vendedores['Ticket_Medio'] = (ranking_vendedores['Receita'] / \n",
    "                                       ranking_vendedores['Qtd_Vendida'])\n",
    "print(ranking_vendedores.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Opera√ß√µes Avan√ßadas - Pivot, Melt, Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table\n",
    "pivot_vendas = pd.pivot_table(\n",
    "    df_vendas,\n",
    "    values='Receita',\n",
    "    index='Regiao',\n",
    "    columns='Produto',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(\"Pivot Table - Receita por Regi√£o e Produto:\")\n",
    "print(pivot_vendas.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar fun√ß√£o customizada\n",
    "def classificar_receita(receita):\n",
    "    if receita < 100000:\n",
    "        return 'Baixa'\n",
    "    elif receita < 300000:\n",
    "        return 'M√©dia'\n",
    "    else:\n",
    "        return 'Alta'\n",
    "\n",
    "df_vendas['ClasseReceita'] = df_vendas['Receita'].apply(classificar_receita)\n",
    "\n",
    "print(\"Distribui√ß√£o por classe de receita:\")\n",
    "print(df_vendas['ClasseReceita'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations\n",
    "df_vendas['Regiao_Upper'] = df_vendas['Regiao'].str.upper()\n",
    "df_vendas['Produto_Lower'] = df_vendas['Produto'].str.lower()\n",
    "df_vendas['Tem_Norte'] = df_vendas['Regiao'].str.contains('Norte')\n",
    "\n",
    "print(\"Registros da regi√£o Norte:\")\n",
    "print(df_vendas[df_vendas['Tem_Norte']].groupby('Regiao')['Receita'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modulo3'></a>\n",
    "# üìä M√≥dulo 3 ‚Äì Visualiza√ß√£o e An√°lise Explorat√≥ria de Dados\n",
    "\n",
    "Visualiza√ß√£o √© parte essencial da ci√™ncia de dados.  \n",
    "Neste m√≥dulo utilizaremos **Matplotlib**, **Seaborn** e **Plotly** para compreender padr√µes e distribui√ß√µes.\n",
    "\n",
    "## 3.1 Matplotlib - Visualiza√ß√µes B√°sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configura√ß√£o de estilo\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma - Distribui√ß√£o de idades no Titanic\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Age'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(df['Age'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'M√©dia: {df[\"Age\"].mean():.1f}')\n",
    "plt.axvline(df['Age'].median(), color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Mediana: {df[\"Age\"].median():.1f}')\n",
    "plt.xlabel('Idade')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.title('Distribui√ß√£o de Idades - Titanic', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de barras - Taxa de sobreviv√™ncia por classe\n",
    "sobrevivencia_classe = df.groupby('Pclass')['Survived'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sobrevivencia_classe.index, sobrevivencia_classe.values, \n",
    "               color=['gold', 'silver', '#CD7F32'], edgecolor='black', alpha=0.8)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xlabel('Classe', fontweight='bold')\n",
    "plt.ylabel('Taxa de Sobreviv√™ncia', fontweight='bold')\n",
    "plt.title('Taxa de Sobreviv√™ncia por Classe - Titanic', fontsize=14, fontweight='bold')\n",
    "plt.xticks([1, 2, 3], ['1¬™ Classe', '2¬™ Classe', '3¬™ Classe'])\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplots - M√∫ltiplos gr√°ficos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Gr√°fico 1: Distribui√ß√£o de idade\n",
    "axes[0, 0].hist(df['Age'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribui√ß√£o de Idades', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Idade')\n",
    "axes[0, 0].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# Gr√°fico 2: Distribui√ß√£o de tarifas\n",
    "axes[0, 1].hist(df['Fare'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribui√ß√£o de Tarifas', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Tarifa')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# Gr√°fico 3: Contagem por classe\n",
    "df['Pclass'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 0], \n",
    "                                               color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Passageiros por Classe', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Classe')\n",
    "axes[1, 0].set_ylabel('Quantidade')\n",
    "axes[1, 0].set_xticklabels(['1¬™ Classe', '2¬™ Classe', '3¬™ Classe'], rotation=0)\n",
    "\n",
    "# Gr√°fico 4: Taxa de sobreviv√™ncia por sexo\n",
    "df.groupby('Sex')['Survived'].mean().plot(kind='bar', ax=axes[1, 1], \n",
    "                                          color=['lightblue', 'pink'], edgecolor='black')\n",
    "axes[1, 1].set_title('Taxa de Sobreviv√™ncia por Sexo', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sexo')\n",
    "axes[1, 1].set_ylabel('Taxa de Sobreviv√™ncia')\n",
    "axes[1, 1].set_xticklabels(['Feminino', 'Masculino'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Seaborn - Visualiza√ß√µes Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot - Distribui√ß√£o de idade por classe e sobreviv√™ncia\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Pclass', y='Age', hue='Survived', data=df, palette='Set2')\n",
    "plt.title('Distribui√ß√£o de Idade por Classe e Sobreviv√™ncia', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe', fontweight='bold')\n",
    "plt.ylabel('Idade', fontweight='bold')\n",
    "plt.legend(title='Sobreviveu', labels=['N√£o', 'Sim'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='Pclass', y='Fare', hue='Sex', data=df, split=True, palette='muted')\n",
    "plt.title('Distribui√ß√£o de Tarifas por Classe e Sexo', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe', fontweight='bold')\n",
    "plt.ylabel('Tarifa', fontweight='bold')\n",
    "plt.legend(title='Sexo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Pclass', hue='Survived', data=df, palette='viridis')\n",
    "plt.title('Contagem de Passageiros por Classe e Sobreviv√™ncia', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe', fontweight='bold')\n",
    "plt.ylabel('Contagem', fontweight='bold')\n",
    "plt.legend(title='Sobreviveu', labels=['N√£o', 'Sim'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de correla√ß√£o\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlacao = df[['Pclass', 'Age', 'Fare', 'Survived']].corr()\n",
    "sns.heatmap(correlacao, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correla√ß√£o - Titanic', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Visualiza√ß√µes com Dados de Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolu√ß√£o temporal de vendas\n",
    "vendas_mensais = df_vendas.groupby(df_vendas['Data'].dt.to_period('M'))['Receita'].sum()\n",
    "vendas_mensais.index = vendas_mensais.index.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(vendas_mensais.index, vendas_mensais.values, marker='o', linewidth=2)\n",
    "plt.fill_between(vendas_mensais.index, vendas_mensais.values, alpha=0.3)\n",
    "plt.title('Evolu√ß√£o Mensal de Receita', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Data', fontweight='bold')\n",
    "plt.ylabel('Receita', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de barras horizontal - Receita por regi√£o\n",
    "receita_regiao = df_vendas.groupby('Regiao')['Receita'].sum().sort_values()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(receita_regiao.index, receita_regiao.values, \n",
    "                color=sns.color_palette('husl', len(receita_regiao)))\n",
    "\n",
    "# Adicionar valores\n",
    "for i, (idx, val) in enumerate(receita_regiao.items()):\n",
    "    plt.text(val, i, f' R$ {val:,.0f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.title('Receita Total por Regi√£o', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Receita (R$)', fontweight='bold')\n",
    "plt.ylabel('Regi√£o', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de pizza - Participa√ß√£o por produto\n",
    "vendas_produto = df_vendas.groupby('Produto')['Receita'].sum()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = sns.color_palette('pastel')\n",
    "plt.pie(vendas_produto.values, labels=vendas_produto.index, autopct='%1.1f%%',\n",
    "        startangle=90, colors=colors, wedgeprops={'edgecolor': 'black'})\n",
    "plt.title('Participa√ß√£o de Cada Produto na Receita Total', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap - Receita por regi√£o e produto\n",
    "pivot_reg_prod = pd.pivot_table(\n",
    "    df_vendas, \n",
    "    values='Receita', \n",
    "    index='Regiao', \n",
    "    columns='Produto', \n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_reg_prod, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            linewidths=0.5, cbar_kws={'label': 'Receita'})\n",
    "plt.title('Receita por Regi√£o e Produto', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Produto', fontweight='bold')\n",
    "plt.ylabel('Regi√£o', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 An√°lise do Dataset de COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e preparar dados de COVID\n",
    "df_covid = pd.read_csv(\"datasets/covid.csv\")\n",
    "df_covid['Data'] = pd.to_datetime(df_covid['Data'])\n",
    "\n",
    "print(\"Dataset COVID-19:\")\n",
    "print(df_covid.head())\n",
    "print(f\"\\nPer√≠odo: {df_covid['Data'].min()} a {df_covid['Data'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolu√ß√£o de casos por regi√£o\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Casos ao longo do tempo\n",
    "for regiao in df_covid['Regiao'].unique():\n",
    "    dados_regiao = df_covid[df_covid['Regiao'] == regiao]\n",
    "    axes[0].plot(dados_regiao['Data'], dados_regiao['Casos'], \n",
    "                 marker='o', label=regiao, linewidth=2)\n",
    "\n",
    "axes[0].set_title('Evolu√ß√£o de Casos de COVID-19 por Regi√£o', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Data', fontweight='bold')\n",
    "axes[0].set_ylabel('Casos', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# √ìbitos ao longo do tempo\n",
    "for regiao in df_covid['Regiao'].unique():\n",
    "    dados_regiao = df_covid[df_covid['Regiao'] == regiao]\n",
    "    axes[1].plot(dados_regiao['Data'], dados_regiao['Obitos'], \n",
    "                 marker='s', label=regiao, linewidth=2)\n",
    "\n",
    "axes[1].set_title('Evolu√ß√£o de √ìbitos por COVID-19 por Regi√£o', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Data', fontweight='bold')\n",
    "axes[1].set_ylabel('√ìbitos', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Totais por regi√£o\n",
    "totais_covid = df_covid.groupby('Regiao').agg({\n",
    "    'Casos': 'sum',\n",
    "    'Obitos': 'sum',\n",
    "    'Vacinados': 'sum'\n",
    "})\n",
    "\n",
    "totais_covid['Taxa_Mortalidade'] = (totais_covid['Obitos'] / totais_covid['Casos'] * 100)\n",
    "totais_covid['Taxa_Vacinacao'] = (totais_covid['Vacinados'] / totais_covid['Casos'] * 100)\n",
    "\n",
    "print(\"Estat√≠sticas Totais de COVID-19 por Regi√£o:\")\n",
    "print(totais_covid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o comparativa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Casos totais por regi√£o\n",
    "totais_covid['Casos'].plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('Total de Casos por Regi√£o', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Regi√£o', fontweight='bold')\n",
    "axes[0].set_ylabel('Casos', fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Taxa de mortalidade por regi√£o\n",
    "totais_covid['Taxa_Mortalidade'].plot(kind='bar', ax=axes[1], color='crimson', edgecolor='black')\n",
    "axes[1].set_title('Taxa de Mortalidade por Regi√£o (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Regi√£o', fontweight='bold')\n",
    "axes[1].set_ylabel('Taxa (%)', fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modulo4'></a>\n",
    "# ‚öôÔ∏è M√≥dulo 4 ‚Äì An√°lise Estat√≠stica e Machine Learning\n",
    "\n",
    "Neste m√≥dulo exploramos an√°lises estat√≠sticas, testes de hip√≥teses e introdu√ß√£o a Machine Learning.\n",
    "\n",
    "## 4.1 Estat√≠stica Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# An√°lise estat√≠stica completa\n",
    "def analise_estatistica(dados, nome_variavel):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"An√°lise Estat√≠stica: {nome_variavel}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nMedidas de Tend√™ncia Central:\")\n",
    "    print(f\"  M√©dia: {np.mean(dados):.2f}\")\n",
    "    print(f\"  Mediana: {np.median(dados):.2f}\")\n",
    "    print(f\"  Moda: {stats.mode(dados, keepdims=True)[0][0]:.2f}\")\n",
    "    \n",
    "    print(f\"\\nMedidas de Dispers√£o:\")\n",
    "    print(f\"  Vari√¢ncia: {np.var(dados):.2f}\")\n",
    "    print(f\"  Desvio Padr√£o: {np.std(dados):.2f}\")\n",
    "    print(f\"  Amplitude: {np.max(dados) - np.min(dados):.2f}\")\n",
    "    print(f\"  IQR: {np.percentile(dados, 75) - np.percentile(dados, 25):.2f}\")\n",
    "    \n",
    "    print(f\"\\nMedidas de Posi√ß√£o:\")\n",
    "    print(f\"  M√≠nimo: {np.min(dados):.2f}\")\n",
    "    print(f\"  Q1 (25%): {np.percentile(dados, 25):.2f}\")\n",
    "    print(f\"  Q2 (50%): {np.percentile(dados, 50):.2f}\")\n",
    "    print(f\"  Q3 (75%): {np.percentile(dados, 75):.2f}\")\n",
    "    print(f\"  M√°ximo: {np.max(dados):.2f}\")\n",
    "    \n",
    "    print(f\"\\nMedidas de Forma:\")\n",
    "    print(f\"  Assimetria (Skewness): {stats.skew(dados):.2f}\")\n",
    "    print(f\"  Curtose (Kurtosis): {stats.kurtosis(dados):.2f}\")\n",
    "\n",
    "# Aplicar an√°lise\n",
    "analise_estatistica(df['Age'].dropna(), 'Idade dos Passageiros do Titanic')\n",
    "analise_estatistica(df['Fare'].dropna(), 'Tarifa dos Passageiros do Titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Testes de Hip√≥teses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste t para amostras independentes\n",
    "# H0: N√£o h√° diferen√ßa na idade m√©dia entre sobreviventes e n√£o sobreviventes\n",
    "\n",
    "idade_sobreviventes = df[df['Survived'] == 1]['Age'].dropna()\n",
    "idade_nao_sobreviventes = df[df['Survived'] == 0]['Age'].dropna()\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(idade_sobreviventes, idade_nao_sobreviventes)\n",
    "\n",
    "print(\"Teste t para Idade: Sobreviventes vs N√£o Sobreviventes\")\n",
    "print(f\"M√©dia - Sobreviventes: {idade_sobreviventes.mean():.2f}\")\n",
    "print(f\"M√©dia - N√£o Sobreviventes: {idade_nao_sobreviventes.mean():.2f}\")\n",
    "print(f\"\\nEstat√≠stica t: {t_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclus√£o: Rejeitamos H0. H√° diferen√ßa significativa nas idades.\")\n",
    "else:\n",
    "    print(\"\\nConclus√£o: N√£o rejeitamos H0. N√£o h√° diferen√ßa significativa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste Qui-Quadrado de Independ√™ncia\n",
    "# H0: Classe e Sobreviv√™ncia s√£o independentes\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "tabela_contingencia = pd.crosstab(df['Pclass'], df['Survived'])\n",
    "print(\"Tabela de Conting√™ncia - Classe x Sobreviv√™ncia:\")\n",
    "print(tabela_contingencia)\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(tabela_contingencia)\n",
    "\n",
    "print(f\"\\nEstat√≠stica Qui-Quadrado: {chi2:.4f}\")\n",
    "print(f\"P-valor: {p_value:.4f}\")\n",
    "print(f\"Graus de liberdade: {dof}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclus√£o: Rejeitamos H0. Classe e sobreviv√™ncia N√ÉO s√£o independentes.\")\n",
    "else:\n",
    "    print(\"\\nConclus√£o: N√£o rejeitamos H0. N√£o h√° evid√™ncia de depend√™ncia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA - Compara√ß√£o de m√∫ltiplos grupos\n",
    "# H0: A m√©dia de tarifa √© igual para todas as classes\n",
    "\n",
    "classe1 = df[df['Pclass'] == 1]['Fare'].dropna()\n",
    "classe2 = df[df['Pclass'] == 2]['Fare'].dropna()\n",
    "classe3 = df[df['Pclass'] == 3]['Fare'].dropna()\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(classe1, classe2, classe3)\n",
    "\n",
    "print(\"ANOVA - Tarifa por Classe\")\n",
    "print(f\"M√©dia Classe 1: {classe1.mean():.2f}\")\n",
    "print(f\"M√©dia Classe 2: {classe2.mean():.2f}\")\n",
    "print(f\"M√©dia Classe 3: {classe3.mean():.2f}\")\n",
    "print(f\"\\nEstat√≠stica F: {f_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclus√£o: Rejeitamos H0. H√° diferen√ßa significativa nas tarifas entre classes.\")\n",
    "else:\n",
    "    print(\"\\nConclus√£o: N√£o rejeitamos H0. N√£o h√° diferen√ßa significativa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de Normalidade\n",
    "stat_shapiro, p_shapiro = stats.shapiro(df['Age'].dropna())\n",
    "\n",
    "print(\"Teste de Normalidade (Shapiro-Wilk) - Idade\")\n",
    "print(f\"Estat√≠stica: {stat_shapiro:.4f}\")\n",
    "print(f\"P-valor: {p_shapiro:.4f}\")\n",
    "\n",
    "if p_shapiro < 0.05:\n",
    "    print(\"\\nConclus√£o: Rejeitamos H0. Os dados N√ÉO seguem distribui√ß√£o normal.\")\n",
    "else:\n",
    "    print(\"\\nConclus√£o: N√£o rejeitamos H0. Os dados seguem distribui√ß√£o normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Correla√ß√£o e Regress√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de correla√ß√£o\n",
    "print(\"Correla√ß√µes (Pearson):\")\n",
    "print(f\"Idade vs Tarifa: {df['Age'].corr(df['Fare']):.4f}\")\n",
    "print(f\"Classe vs Sobreviv√™ncia: {df['Pclass'].corr(df['Survived']):.4f}\")\n",
    "\n",
    "# Correla√ß√£o de Spearman (n√£o linear)\n",
    "spearman_corr, spearman_p = stats.spearmanr(df['Pclass'], df['Survived'])\n",
    "print(f\"\\nCorrela√ß√£o de Spearman (Classe vs Sobreviv√™ncia): {spearman_corr:.4f}\")\n",
    "print(f\"P-valor: {spearman_p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress√£o Linear Simples\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Preparar dados (remover NaN)\n",
    "dados_regressao = df[['Age', 'Fare']].dropna()\n",
    "X = dados_regressao[['Age']].values\n",
    "y = dados_regressao['Fare'].values\n",
    "\n",
    "# Criar e treinar modelo\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_lr.fit(X, y)\n",
    "\n",
    "# Predi√ß√µes\n",
    "y_pred = modelo_lr.predict(X)\n",
    "\n",
    "# M√©tricas\n",
    "print(\"Regress√£o Linear: Idade ‚Üí Tarifa\")\n",
    "print(f\"Intercepto: {modelo_lr.intercept_:.2f}\")\n",
    "print(f\"Coeficiente: {modelo_lr.coef_[0]:.2f}\")\n",
    "print(f\"\\nR¬≤ Score: {r2_score(y, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o da regress√£o\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.5, label='Dados reais')\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label='Linha de regress√£o')\n",
    "plt.xlabel('Idade', fontweight='bold')\n",
    "plt.ylabel('Tarifa', fontweight='bold')\n",
    "plt.title(f'Regress√£o Linear: Idade vs Tarifa (R¬≤ = {r2_score(y, y_pred):.3f})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Machine Learning - Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Preparar dados para classifica√ß√£o\n",
    "df_ml = df[['Pclass', 'Sex', 'Age', 'Fare', 'Survived']].copy()\n",
    "df_ml = df_ml.dropna()\n",
    "\n",
    "# Encoding de vari√°vel categ√≥rica\n",
    "df_ml['Sex_encoded'] = df_ml['Sex'].map({'Masculino': 0, 'Feminino': 1})\n",
    "\n",
    "# Features e target\n",
    "X = df_ml[['Pclass', 'Sex_encoded', 'Age', 'Fare']]\n",
    "y = df_ml['Survived']\n",
    "\n",
    "# Divis√£o treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Dados de treino: {X_train.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"\\nDistribui√ß√£o da classe (treino):\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Regress√£o Log√≠stica\n",
    "modelo_lr = LogisticRegression(random_state=42)\n",
    "modelo_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = modelo_lr.predict(X_test_scaled)\n",
    "acuracia_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"REGRESS√ÉO LOG√çSTICA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAcur√°cia: {acuracia_lr:.3f}\")\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_lr, \n",
    "                          target_names=['N√£o Sobreviveu', 'Sobreviveu']))\n",
    "\n",
    "# Matriz de confus√£o\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['N√£o Sobreviveu', 'Sobreviveu'],\n",
    "            yticklabels=['N√£o Sobreviveu', 'Sobreviveu'])\n",
    "plt.title('Matriz de Confus√£o - Regress√£o Log√≠stica', fontweight='bold')\n",
    "plt.ylabel('Real', fontweight='bold')\n",
    "plt.xlabel('Predito', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Random Forest\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = modelo_rf.predict(X_test_scaled)\n",
    "acuracia_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAcur√°cia: {acuracia_rf:.3f}\")\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                          target_names=['N√£o Sobreviveu', 'Sobreviveu']))\n",
    "\n",
    "# Feature importance\n",
    "importancias = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Import√¢ncia': modelo_rf.feature_importances_\n",
    "}).sort_values('Import√¢ncia', ascending=False)\n",
    "\n",
    "print(\"\\nImport√¢ncia das Features:\")\n",
    "print(importancias)\n",
    "\n",
    "# Visualizar import√¢ncia\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Import√¢ncia', y='Feature', data=importancias, palette='viridis')\n",
    "plt.title('Import√¢ncia das Features - Random Forest', fontweight='bold')\n",
    "plt.xlabel('Import√¢ncia', fontweight='bold')\n",
    "plt.ylabel('Feature', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Probabilidades\n",
    "y_proba_lr = modelo_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "y_proba_rf = modelo_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular ROC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "\n",
    "auc_lr = roc_auc_score(y_test, y_proba_lr)\n",
    "auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, linewidth=2, label=f'Regress√£o Log√≠stica (AUC = {auc_lr:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, linewidth=2, label=f'Random Forest (AUC = {auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)')\n",
    "plt.xlabel('Taxa de Falsos Positivos', fontweight='bold')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos', fontweight='bold')\n",
    "plt.title('Curva ROC - Compara√ß√£o de Modelos', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o Cruzada\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Regress√£o Log√≠stica\n",
    "scores_lr = cross_val_score(modelo_lr, X_train_scaled, y_train, \n",
    "                             cv=kfold, scoring='accuracy')\n",
    "print(\"Valida√ß√£o Cruzada - Regress√£o Log√≠stica\")\n",
    "print(f\"Scores: {scores_lr}\")\n",
    "print(f\"M√©dia: {scores_lr.mean():.3f} (+/- {scores_lr.std():.3f})\")\n",
    "\n",
    "# Random Forest\n",
    "scores_rf = cross_val_score(modelo_rf, X_train_scaled, y_train, \n",
    "                             cv=kfold, scoring='accuracy')\n",
    "print(\"\\nValida√ß√£o Cruzada - Random Forest\")\n",
    "print(f\"Scores: {scores_rf}\")\n",
    "print(f\"M√©dia: {scores_rf.mean():.3f} (+/- {scores_rf.std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Clustering - An√°lise de Filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset de filmes\n",
    "df_filmes = pd.read_csv(\"datasets/filmes.csv\")\n",
    "print(\"Dataset de Filmes:\")\n",
    "print(df_filmes.head())\n",
    "print(f\"\\nTotal de filmes: {len(df_filmes)}\")\n",
    "print(f\"G√™neros √∫nicos: {df_filmes['Genero'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Preparar dados para clustering\n",
    "X_cluster = df_filmes[['Ano', 'Nota', 'Popularidade']].copy()\n",
    "\n",
    "# Normalizar\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "# M√©todo do cotovelo\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))\n",
    "\n",
    "# Visualizar m√©todo do cotovelo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('N√∫mero de Clusters', fontweight='bold')\n",
    "axes[0].set_ylabel('In√©rcia', fontweight='bold')\n",
    "axes[0].set_title('M√©todo do Cotovelo', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, 'ro-', linewidth=2)\n",
    "axes[1].set_xlabel('N√∫mero de Clusters', fontweight='bold')\n",
    "axes[1].set_ylabel('Silhouette Score', fontweight='bold')\n",
    "axes[1].set_title('Silhouette Score por N√∫mero de Clusters', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means com k=4\n",
    "kmeans_final = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df_filmes['Cluster'] = kmeans_final.fit_predict(X_cluster_scaled)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette_score(X_cluster_scaled, df_filmes['Cluster']):.3f}\")\n",
    "print(\"\\nDistribui√ß√£o de filmes por cluster:\")\n",
    "print(df_filmes['Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCaracter√≠sticas m√©dias por cluster:\")\n",
    "print(df_filmes.groupby('Cluster')[['Ano', 'Nota', 'Popularidade']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar clusters\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Nota vs Popularidade\n",
    "ax1 = fig.add_subplot(131)\n",
    "scatter1 = ax1.scatter(df_filmes['Nota'], df_filmes['Popularidade'], \n",
    "                        c=df_filmes['Cluster'], cmap='viridis', alpha=0.6)\n",
    "ax1.set_xlabel('Nota', fontweight='bold')\n",
    "ax1.set_ylabel('Popularidade', fontweight='bold')\n",
    "ax1.set_title('Clusters: Nota vs Popularidade', fontweight='bold')\n",
    "plt.colorbar(scatter1, ax=ax1, label='Cluster')\n",
    "\n",
    "# Plot 2: Ano vs Nota\n",
    "ax2 = fig.add_subplot(132)\n",
    "scatter2 = ax2.scatter(df_filmes['Ano'], df_filmes['Nota'], \n",
    "                        c=df_filmes['Cluster'], cmap='viridis', alpha=0.6)\n",
    "ax2.set_xlabel('Ano', fontweight='bold')\n",
    "ax2.set_ylabel('Nota', fontweight='bold')\n",
    "ax2.set_title('Clusters: Ano vs Nota', fontweight='bold')\n",
    "plt.colorbar(scatter2, ax=ax2, label='Cluster')\n",
    "\n",
    "# Plot 3: Ano vs Popularidade\n",
    "ax3 = fig.add_subplot(133)\n",
    "scatter3 = ax3.scatter(df_filmes['Ano'], df_filmes['Popularidade'], \n",
    "                        c=df_filmes['Cluster'], cmap='viridis', alpha=0.6)\n",
    "ax3.set_xlabel('Ano', fontweight='bold')\n",
    "ax3.set_ylabel('Popularidade', fontweight='bold')\n",
    "ax3.set_title('Clusters: Ano vs Popularidade', fontweight='bold')\n",
    "plt.colorbar(scatter3, ax=ax3, label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modulo5'></a>\n",
    "# üéì M√≥dulo 5 ‚Äì Projeto Final Integrado\n",
    "\n",
    "Neste m√≥dulo, voc√™ deve escolher um dos datasets dispon√≠veis e desenvolver uma an√°lise completa.\n",
    "\n",
    "## Datasets Dispon√≠veis\n",
    "\n",
    "1. **titanic.csv** - An√°lise de sobreviv√™ncia de passageiros\n",
    "2. **vendas.csv** - An√°lise de vendas regionais e desempenho de produtos\n",
    "3. **ibge_populacao.csv** - Indicadores populacionais e varia√ß√£o temporal\n",
    "4. **covid.csv** - Casos, √≥bitos e taxas de vacina√ß√£o\n",
    "5. **filmes.csv** - Notas m√©dias, popularidade e g√™neros\n",
    "\n",
    "## Estrutura do Projeto Final\n",
    "\n",
    "Seu projeto deve incluir:\n",
    "\n",
    "### 1. Introdu√ß√£o\n",
    "- Contexto do problema\n",
    "- Objetivos da an√°lise\n",
    "- Perguntas que ser√£o respondidas\n",
    "\n",
    "### 2. Explora√ß√£o dos Dados\n",
    "- Carregamento e visualiza√ß√£o inicial\n",
    "- Estat√≠sticas descritivas\n",
    "- Identifica√ß√£o de valores ausentes e outliers\n",
    "\n",
    "### 3. Limpeza e Prepara√ß√£o\n",
    "- Tratamento de valores ausentes\n",
    "- Remo√ß√£o de duplicatas\n",
    "- Cria√ß√£o de novas features (feature engineering)\n",
    "- Transforma√ß√µes necess√°rias\n",
    "\n",
    "### 4. An√°lise Explorat√≥ria (EDA)\n",
    "- Visualiza√ß√µes relevantes\n",
    "- An√°lise de distribui√ß√µes\n",
    "- Identifica√ß√£o de padr√µes e tend√™ncias\n",
    "- An√°lise de correla√ß√µes\n",
    "\n",
    "### 5. An√°lise Estat√≠stica\n",
    "- Testes de hip√≥teses apropriados\n",
    "- An√°lise de signific√¢ncia\n",
    "- Intervalos de confian√ßa\n",
    "\n",
    "### 6. Modelagem (opcional)\n",
    "- Modelo preditivo ou de clustering\n",
    "- Avalia√ß√£o de desempenho\n",
    "- Interpreta√ß√£o dos resultados\n",
    "\n",
    "### 7. Insights e Conclus√µes\n",
    "- Principais descobertas\n",
    "- Resposta √†s perguntas iniciais\n",
    "- Recomenda√ß√µes baseadas na an√°lise\n",
    "- Limita√ß√µes do estudo\n",
    "\n",
    "### 8. Documenta√ß√£o\n",
    "- C√≥digo bem comentado\n",
    "- Explica√ß√µes claras das escolhas metodol√≥gicas\n",
    "- Refer√™ncias utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de Estrutura - An√°lise de Popula√ß√£o IBGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "df_ibge = pd.read_csv(\"datasets/ibge_populacao.csv\")\n",
    "\n",
    "print(\"Dataset IBGE - Popula√ß√£o:\")\n",
    "print(df_ibge.head())\n",
    "print(f\"\\nPer√≠odo: {df_ibge['Ano'].min()} a {df_ibge['Ano'].max()}\")\n",
    "print(f\"\\nRegi√µes: {df_ibge['Regiao'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise por regi√£o\n",
    "print(\"Popula√ß√£o Total por Regi√£o (2024):\")\n",
    "pop_2024 = df_ibge[df_ibge['Ano'] == df_ibge['Ano'].max()]\n",
    "print(pop_2024.sort_values('Populacao', ascending=False))\n",
    "\n",
    "# Crescimento populacional\n",
    "pivot_ibge = df_ibge.pivot(index='Ano', columns='Regiao', values='Populacao')\n",
    "print(\"\\nCrescimento Populacional por Regi√£o:\")\n",
    "crescimento = ((pivot_ibge.loc[pivot_ibge.index.max()] - \n",
    "                pivot_ibge.loc[pivot_ibge.index.min()]) / \n",
    "               pivot_ibge.loc[pivot_ibge.index.min()] * 100)\n",
    "print(crescimento.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o da evolu√ß√£o populacional\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for regiao in df_ibge['Regiao'].unique():\n",
    "    dados_regiao = df_ibge[df_ibge['Regiao'] == regiao]\n",
    "    plt.plot(dados_regiao['Ano'], dados_regiao['Populacao'], \n",
    "             marker='o', linewidth=2, label=regiao)\n",
    "\n",
    "plt.title('Evolu√ß√£o Populacional por Regi√£o (2015-2024)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Ano', fontweight='bold')\n",
    "plt.ylabel('Popula√ß√£o', fontweight='bold')\n",
    "plt.legend(title='Regi√£o', loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espa√ßo para Seu Projeto Final\n",
    "\n",
    "Use as c√©lulas abaixo para desenvolver seu projeto final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu c√≥digo aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclus√£o\n",
    "\n",
    "Este notebook forneceu uma base t√©cnica s√≥lida em programa√ß√£o e manipula√ß√£o de dados com Python, integrando:\n",
    "\n",
    "- **Fundamentos de Python**: Estruturas de dados, fun√ß√µes, compreens√µes\n",
    "- **NumPy**: Computa√ß√£o num√©rica eficiente\n",
    "- **Pandas**: Manipula√ß√£o e an√°lise de dados tabulares\n",
    "- **Visualiza√ß√£o**: Matplotlib e Seaborn para insights visuais\n",
    "- **Estat√≠stica**: Testes de hip√≥teses e an√°lises estat√≠sticas\n",
    "- **Machine Learning**: Classifica√ß√£o, regress√£o e clustering\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "1. Completar o projeto final escolhido\n",
    "2. Explorar t√©cnicas avan√ßadas de feature engineering\n",
    "3. Aprofundar em algoritmos de Machine Learning\n",
    "4. Estudar Deep Learning e redes neurais\n",
    "5. Desenvolver projetos pr√≥prios\n",
    "\n",
    "### Recursos Adicionais\n",
    "\n",
    "- Documenta√ß√£o oficial: [pandas.pydata.org](https://pandas.pydata.org)\n",
    "- Scikit-learn: [scikit-learn.org](https://scikit-learn.org)\n",
    "- Kaggle: [kaggle.com](https://kaggle.com) - datasets e competi√ß√µes\n",
    "\n",
    "**Bons estudos e boa an√°lise de dados!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
